{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Luiz Ricardo Hardman Paranhos\n",
    "\n",
    "Nome: Matheus Kwon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo cheetos.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'cheetos.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@eaipaixao_ cheetos obv</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@giovannapinto mano eu fui comprar 2 cheetos e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@zabele__ s√≥ tenho cheetos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@lilizvante cheetos, old\\nhttps://t.co/atamf2woj7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@biaventura14 kkkkkkkkkkkkkkkkkkkkk cheetos ve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  relevancia\n",
       "0                            @eaipaixao_ cheetos obv           2\n",
       "1  @giovannapinto mano eu fui comprar 2 cheetos e...           2\n",
       "2                         @zabele__ s√≥ tenho cheetos           1\n",
       "3  @lilizvante cheetos, old\\nhttps://t.co/atamf2woj7           1\n",
       "4  @biaventura14 kkkkkkkkkkkkkkkkkkkkk cheetos ve...           2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sou do tipo que quando t√° conversando com algu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>att fresquinha de flaming hot cheetos!!!! http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>me entupindo de cheetos enquanto vejo tapas e ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cheetos ou doritos https://t.co/caytqjylnp</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mas quem colocou o cheetos na minha tml hoje ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  relevancia\n",
       "0  sou do tipo que quando t√° conversando com algu...           0\n",
       "1  att fresquinha de flaming hot cheetos!!!! http...           1\n",
       "2  me entupindo de cheetos enquanto vejo tapas e ...           1\n",
       "3         cheetos ou doritos https://t.co/caytqjylnp           2\n",
       "4     mas quem colocou o cheetos na minha tml hoje ?           2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "- Relevante: informa√ß√£o da qual a empresa pode ganhar dinheiro\n",
    "- Neutro: informa√ß√µes sobre o salgadinho cheetos, mas que n√£o necessariamente interessa √† empresa\n",
    "- Irrelevante: resto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['relevancia'] = train['relevancia'].astype('category')\n",
    "train.relevancia.cat.categories = ['irrelevante', 'neutro', 'relevante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    # Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    # import string\n",
    "    punctuation = '[!-.:?;/,_@¬ø]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "def cleanup_enter(text):\n",
    "    punctuation = '\\n'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "def deEmojify(text):\n",
    "    # retirado do stackoverflow\n",
    "    em_split_emoji = emoji.get_emoji_regexp().split(text)\n",
    "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "    em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "    p = ''\n",
    "    for separated in em_split:\n",
    "        p += separated + ' '\n",
    "    return p\n",
    "#    regrex_pattern = re.compile(pattern = \"[\"\n",
    "#        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                            \"]+\", flags = re.UNICODE)\n",
    "#    return regrex_pattern.sub(r'',text)\n",
    "    \n",
    "\n",
    "def link(text):\n",
    "    text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'@\\S+', '', text, flags=re.MULTILINE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# String com todas as palavras\n",
    "tweets_treinamento_raw = ''\n",
    "for tweet in train.Treinamento:\n",
    "    tweets_treinamento_raw = tweets_treinamento_raw + ' ' + tweet\n",
    "tweets_treinamento = deEmojify(cleanup_enter(cleanup(link(tweets_treinamento_raw.lower()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String com os relevantes\n",
    "filtro_relevante_train = train.relevancia == 'relevante'\n",
    "treinamento_relevante = train.loc[filtro_relevante_train,:]\n",
    "\n",
    "tweets_relevantes = ''\n",
    "for tweet in treinamento_relevante.Treinamento:\n",
    "    tweets_relevantes = tweets_relevantes + ' ' + tweet\n",
    "\n",
    "treinamento_relevante = deEmojify(cleanup_enter(cleanup(link(tweets_relevantes.lower()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String com os irrelevantes\n",
    "filtro_irrelevante_train = train.relevancia == 'irrelevante'\n",
    "treinamento_irrelevante = train.loc[filtro_irrelevante_train,:]\n",
    "\n",
    "tweets_irrelevantes = ''\n",
    "for tweet in treinamento_irrelevante.Treinamento:\n",
    "    tweets_irrelevantes = tweets_irrelevantes + ' ' + tweet\n",
    "\n",
    "    \n",
    "treinamento_irrelevante = deEmojify(cleanup_enter(cleanup(tweets_irrelevantes.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String com os neutros\n",
    "filtro_neutro_train = train.relevancia == 'neutro'\n",
    "treinamento_neutro = train.loc[filtro_neutro_train,:]\n",
    "\n",
    "tweets_neutro = ''\n",
    "for tweet in treinamento_neutro.Treinamento:\n",
    "    tweets_neutro = tweets_neutro + ' ' + tweet\n",
    "\n",
    "    \n",
    "treinamento_neutro = deEmojify(cleanup_enter(cleanup(tweets_neutro.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando lista e s√©ries a partir das strings\n",
    "tweets_treinamento_lista = tweets_treinamento.split()\n",
    "treinamento_relevante_lista = treinamento_relevante.split()\n",
    "treinamento_irrelevante_lista = treinamento_irrelevante.split()\n",
    "treinamento_neutro_lista = treinamento_neutro.split()\n",
    "\n",
    "\n",
    "serie_treinamento = pd.Series(tweets_treinamento_lista)\n",
    "serie_treinamento_relevante = pd.Series(treinamento_relevante_lista)\n",
    "serie_treinamento_irrelevante = pd.Series(treinamento_irrelevante_lista)\n",
    "serie_treinamento_neutro = pd.Series(treinamento_neutro_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos    297\n",
       "de         171\n",
       "e          116\n",
       "um          81\n",
       "o           81\n",
       "          ... \n",
       "ponto        1\n",
       "veio         1\n",
       "formato      1\n",
       "find         1\n",
       "zero         1\n",
       "Length: 1261, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_treinamento = serie_treinamento.value_counts()\n",
    "tabela_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos      86\n",
       "de           49\n",
       "e            23\n",
       "requeij√£o    19\n",
       "o            18\n",
       "             ..\n",
       "ü§Ø             1\n",
       "my            1\n",
       "ja            1\n",
       "sensa√ß√£o      1\n",
       "frita         1\n",
       "Length: 287, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_treinamento_relevante = serie_treinamento_relevante.value_counts()\n",
    "tabela_treinamento_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['por', 'se','uma','em','mais','q','que','na','da','do','no','eu','de','e','o','um','a','com','pra', 'mas', 's√≥', 'so']\n",
    "def remove_stopwords(lista):\n",
    "    nova_lista = []\n",
    "    for palavra in lista:\n",
    "        x = 0\n",
    "        if palavra in stopwords:\n",
    "            x = 1\n",
    "        if x == 0:\n",
    "            # transformando verbos no ger√∫ndio em verbos no infinitivo\n",
    "            if palavra[-3:] == 'ndo' or palavra[-3:] == 'mos':\n",
    "                if palavra == 'quando' or palavra == 'mando':\n",
    "                    nova_lista.append(palavra)\n",
    "                else:\n",
    "                    nova_lista.append(palavra[:-3]+'r')\n",
    "            elif palavra == 'n' or palavra == 'nao':\n",
    "                nova_lista.append('n√£o')\n",
    "            elif palavra == 'ta' or palavra =='t√°':\n",
    "                nova_lista.append('est√°')\n",
    "            else:\n",
    "                nova_lista.append(palavra)\n",
    "    return nova_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos      297\n",
       "√©             60\n",
       "n√£o           50\n",
       "comer         38\n",
       "requeij√£o     31\n",
       "doritos       26\n",
       "tem           26\n",
       "meu           23\n",
       "me            19\n",
       "gosto         14\n",
       "pq            13\n",
       "melhor        13\n",
       "vou           12\n",
       "minha         12\n",
       "cheiro        12\n",
       "vontade       12\n",
       "queijo        11\n",
       "est√°          11\n",
       "como          11\n",
       "pacote        10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_treinamento_stopwords_lista = remove_stopwords(tweets_treinamento_lista)\n",
    "        \n",
    "\n",
    "serie_treinamento_filtrado = pd.Series(tweets_treinamento_stopwords_lista)\n",
    "tabela_treinamento_filtrado = serie_treinamento_filtrado.value_counts()\n",
    "tabela_treinamento_filtrado_relativa = serie_treinamento_filtrado.value_counts(True)\n",
    "tabela_treinamento_filtrado.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos       86\n",
       "requeij√£o     19\n",
       "√©             18\n",
       "doritos       16\n",
       "comer         13\n",
       "melhor        11\n",
       "vontade        9\n",
       "fandangos      8\n",
       "queria         7\n",
       "gosto          7\n",
       "üòã              6\n",
       "sabor          5\n",
       "n√£o            5\n",
       "bom            5\n",
       "pq             4\n",
       "eh             4\n",
       "salgadinho     4\n",
       "ü§§              4\n",
       "ruim           4\n",
       "nada           3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo stop words da lista de todas as palavras relevantes\n",
    "treinamento_relevante_stopwords_lista = remove_stopwords(treinamento_relevante_lista)\n",
    "\n",
    "serie_treinamento_relevante_filtrado = pd.Series(treinamento_relevante_stopwords_lista)\n",
    "tabela_treinamento_relevante_filtrado = serie_treinamento_relevante_filtrado.value_counts()\n",
    "tabela_treinamento_relevante_filtrado_relativa = serie_treinamento_relevante_filtrado.value_counts(True)\n",
    "tabela_treinamento_relevante_filtrado.head(20)\n",
    "# palavras_relevantes_totais = len(tabela_treinamento_relevante_filtrado)\n",
    "# primeiras_relevantes = tabela_treinamento_relevante_filtrado.head(20)\n",
    "# P_Palavras = {}\n",
    "# for palavras, valor in primeiras_relevantes.items():\n",
    "#     P_Palavras[palavra] = (valor + 1) / (palavras_totais + palavras_relevantes_totais)\n",
    "# print(P_Palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos    116\n",
       "n√£o         32\n",
       "√©           24\n",
       "tem         13\n",
       "me          11\n",
       "meu         11\n",
       "cheiro      10\n",
       "comer        8\n",
       "est√°         8\n",
       "minha        7\n",
       "seu          7\n",
       "vou          7\n",
       "ele          7\n",
       "pq           6\n",
       "tipo         6\n",
       "aqui         6\n",
       "como         6\n",
       "pelo         5\n",
       "estar        5\n",
       "üò≠            5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo stop words da lista de todas as palavras irrelevantes\n",
    "treinamento_irrelevante_stopwords_lista = remove_stopwords(treinamento_irrelevante_lista)\n",
    "\n",
    "serie_treinamento_irrelevante_filtrado = pd.Series(treinamento_irrelevante_stopwords_lista)\n",
    "tabela_treinamento_irrelevante_filtrado = serie_treinamento_irrelevante_filtrado.value_counts()\n",
    "tabela_treinamento_irrelevante_filtrado_relativa = serie_treinamento_irrelevante_filtrado.value_counts(True)\n",
    "tabela_treinamento_irrelevante_filtrado.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos       95\n",
       "√©             18\n",
       "comer         17\n",
       "n√£o           13\n",
       "tem           11\n",
       "requeij√£o     10\n",
       "meu            9\n",
       "me             8\n",
       "doritos        7\n",
       "as             6\n",
       "1              5\n",
       "pacote         5\n",
       "gosto          5\n",
       "comprar        4\n",
       "comi           4\n",
       "mim            4\n",
       "tudo           4\n",
       "salgadinho     4\n",
       "biscoito       4\n",
       "caf√©           4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treinamento_neutro_stopwords_lista = remove_stopwords(treinamento_neutro_lista)\n",
    "\n",
    "serie_treinamento_neutro_filtrado = pd.Series(treinamento_neutro_stopwords_lista)\n",
    "tabela_treinamento_neutro_filtrado = serie_treinamento_neutro_filtrado.value_counts()\n",
    "tabela_treinamento_neutro_filtrado_relativa = serie_treinamento_neutro_filtrado.value_counts(True)\n",
    "tabela_treinamento_neutro_filtrado.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sou do tipo que quando t√° conversando com algu...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>att fresquinha de flaming hot cheetos!!!! http...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>me entupindo de cheetos enquanto vejo tapas e ...</td>\n",
       "      <td>1</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cheetos ou doritos https://t.co/caytqjylnp</td>\n",
       "      <td>2</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mas quem colocou o cheetos na minha tml hoje ?</td>\n",
       "      <td>2</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>@bebediaboo eu muito li \"anti-cheetos\"</td>\n",
       "      <td>0</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>salgadinho, cheetos, biscoito recheado, biscoi...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>queria experimentar takis e hot cheetos</td>\n",
       "      <td>1</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>@lwttersondre cheetos de requeij√£o &amp;gt;&amp;gt;&amp;gt...</td>\n",
       "      <td>2</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>o cheetos azul √© o melhor de todos e se voc√™ n...</td>\n",
       "      <td>2</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  relevancia  \\\n",
       "0    sou do tipo que quando t√° conversando com algu...           0   \n",
       "1    att fresquinha de flaming hot cheetos!!!! http...           1   \n",
       "2    me entupindo de cheetos enquanto vejo tapas e ...           1   \n",
       "3           cheetos ou doritos https://t.co/caytqjylnp           2   \n",
       "4       mas quem colocou o cheetos na minha tml hoje ?           2   \n",
       "..                                                 ...         ...   \n",
       "195             @bebediaboo eu muito li \"anti-cheetos\"           0   \n",
       "196  salgadinho, cheetos, biscoito recheado, biscoi...           0   \n",
       "197            queria experimentar takis e hot cheetos           1   \n",
       "198  @lwttersondre cheetos de requeij√£o &gt;&gt;&gt...           2   \n",
       "199  o cheetos azul √© o melhor de todos e se voc√™ n...           2   \n",
       "\n",
       "    classificador  \n",
       "0          neutro  \n",
       "1          neutro  \n",
       "2     irrelevante  \n",
       "3       relevante  \n",
       "4     irrelevante  \n",
       "..            ...  \n",
       "195     relevante  \n",
       "196        neutro  \n",
       "197        neutro  \n",
       "198     relevante  \n",
       "199     relevante  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_R = len(treinamento_relevante_stopwords_lista) / len(tweets_treinamento_stopwords_lista)\n",
    "P_Rc = len(treinamento_irrelevante_stopwords_lista) / len(tweets_treinamento_stopwords_lista)\n",
    "P_N = len(treinamento_neutro_stopwords_lista) / len(tweets_treinamento_stopwords_lista)\n",
    "classificador = []\n",
    "def testar (tweet):\n",
    "    P_tweetDadoR = 1\n",
    "    P_tweetDadoRc = 1\n",
    "    P_tweetDadoN = 1\n",
    "    for palavra in tweet_teste:\n",
    "        # verifica se a palavra existe no relevante\n",
    "        if palavra in tabela_treinamento_relevante_filtrado:\n",
    "            P_tweetDadoR = P_tweetDadoR*(tabela_treinamento_relevante_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_relevante_filtrado))\n",
    "            # verifica se a palavra existe no irrelevante e no relevante\n",
    "            if palavra in tabela_treinamento_irrelevante_filtrado:\n",
    "                P_tweetDadoRc = P_tweetDadoRc*(tabela_treinamento_irrelevante_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_irrelevante_filtrado))\n",
    "                # verifica se a palavra existe no irrelevante, neutro e relevante\n",
    "                if palavra in tabela_treinamento_neutro_filtrado:\n",
    "                    P_tweetDadoN = P_tweetDadoN*(tabela_treinamento_neutro_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "                # se n√£o existe a palavra no neutro, considera-se frequ√™ncia 0\n",
    "                else:\n",
    "                    P_tweetDadoN = P_tweetDadoN / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "            # se n√£o existe a palavra no irrelevante, considera-se frequencia 0\n",
    "            else:\n",
    "                P_tweetDadoRc = P_tweetDadoRc / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_irrelevante_filtrado)) \n",
    "                 # verifica se a palavra existe no neutro e relevante\n",
    "                if palavra in tabela_treinamento_neutro_filtrado:\n",
    "                    P_tweetDadoN = P_tweetDadoN*(tabela_treinamento_neutro_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "                # se n√£o existe a palavra no neutro, considera-se frequ√™ncia 0\n",
    "                else:\n",
    "                    P_tweetDadoN = P_tweetDadoN / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "        else:\n",
    "            # se n existe a palavra no relevante, considera-se frequ√™ncia 0\n",
    "            P_tweetDadoR = P_tweetDadoR / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_relevante_filtrado))\n",
    "             # verifica se a palavra existe no irrelevante\n",
    "            if palavra in tabela_treinamento_irrelevante_filtrado:\n",
    "                P_tweetDadoRc = P_tweetDadoRc*(tabela_treinamento_irrelevante_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_irrelevante_filtrado))\n",
    "                 # verifica se a palavra existe no irrelevante e neutro \n",
    "                if palavra in tabela_treinamento_neutro_filtrado:\n",
    "                    P_tweetDadoN = P_tweetDadoN*(tabela_treinamento_neutro_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "                # se n√£o existe a palavra no neutro, considera-se frequ√™ncia 0\n",
    "                else:\n",
    "                    P_tweetDadoN = P_tweetDadoN / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "\n",
    "            # se n existe a palavra no irrelevante, considera-se frequ√™ncia 0\n",
    "            else:\n",
    "                P_tweetDadoRc = P_tweetDadoRc / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_irrelevante_filtrado))\n",
    "                 # verifica se a palavra existe no neutro\n",
    "                if palavra in tabela_treinamento_neutro_filtrado:\n",
    "                    P_tweetDadoN = P_tweetDadoN*(tabela_treinamento_neutro_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "                # se n√£o existe a palavra no neutro, considera-se frequ√™ncia 0\n",
    "                else:\n",
    "                    P_tweetDadoN = P_tweetDadoN / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "    P_RDadoTweet = P_tweetDadoR * P_R\n",
    "    P_RcDadoTweet = P_tweetDadoRc * P_Rc\n",
    "    P_NdadoTweet = P_tweetDadoN * P_N\n",
    "    if P_RDadoTweet >= P_RcDadoTweet:\n",
    "        if P_RDadoTweet >=  P_NdadoTweet:\n",
    "            classificador.append('relevante')\n",
    "        else:\n",
    "            classificador.append('neutro')\n",
    "    else:\n",
    "        if P_RcDadoTweet > P_NdadoTweet:\n",
    "            classificador.append('irrelevante')\n",
    "        else:\n",
    "            classificador.append('neutro')\n",
    "\n",
    "for tweet in test.Teste:\n",
    "    tweet_teste = remove_stopwords(deEmojify(cleanup_enter(cleanup(link(tweet.lower())))).split())\n",
    "    testar(tweet_teste)\n",
    "test['classificador'] = classificador\n",
    "test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classificador</th>\n",
       "      <th>irrelevante</th>\n",
       "      <th>neutro</th>\n",
       "      <th>relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.229730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.189189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.581081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classificador  irrelevante    neutro  relevante\n",
       "relevancia                                     \n",
       "0                 0.573529  0.362069   0.229730\n",
       "1                 0.279412  0.362069   0.189189\n",
       "2                 0.147059  0.275862   0.581081"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimento = pd.crosstab(test.relevancia, test.classificador, normalize='columns')\n",
    "sentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros irrelevantes: 57.353%\n",
      "Verdadeiros neutros: 36.207%\n",
      "Verdadeiros relevantes: 58.108%\n",
      "-----------------------------------------------------------------------\n",
      "Falsos irrelevantes: 42.647%\n",
      "Falsos neutros: 63.793%\n",
      "Falsos relevantes: 41.892%\n"
     ]
    }
   ],
   "source": [
    "# Relat√≥rio resumo\n",
    "\n",
    "# Verdadeiros resultados\n",
    "\n",
    "print (f'Verdadeiros irrelevantes: {(sentimento.irrelevante[0]*100).round(3)}%')\n",
    "print (f'Verdadeiros neutros: {(sentimento.neutro[1]*100).round(3)}%')\n",
    "print (f'Verdadeiros relevantes: {(sentimento.relevante[2]*100).round(3)}%')\n",
    "\n",
    "print('-----------------------------------------------------------------------')\n",
    "\n",
    "# Falsos resultados\n",
    "\n",
    "print (f'Falsos irrelevantes: {((sentimento.irrelevante[1] + sentimento.irrelevante[2])*100).round(3)}%')\n",
    "print (f'Falsos neutros: {((sentimento.neutro[2] + sentimento.neutro[1])*100).round(3)}%')\n",
    "print (f'Falsos relevantes: {((sentimento.relevante[1] + sentimento.relevante[0])*100).round(3)}%')\n",
    "\n",
    "\n",
    "print('-----------------------------------------------------------------------')\n",
    "\n",
    "# Quantas vezes nosso classificador acertou\n",
    "\n",
    "print(f'Acertou em: {(sentimento.irrelevante[0] + sentimento.relevante[2] + sentimento.irrelevante[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre o classificador:\n",
    "- O nosso classificador tem uma performance razo√°vel para classificar tweets relevantes e irrelevantes. No entanto, dentre os tweets classificados como neutros, h√° uma d√∫vida maior em se ele realmente √© neutro ou se ele √©, na verdade, irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como s√£o tratadas mensagens de dupla nega√ß√£o ou sarcasmo:\n",
    "- Quanto aos tweets que cont√©m dupla nega√ß√£o e sarcasmo, nosso classificador funcionar√° na maioria das vezes, pois tweets que cont√©m palavras de nega√ß√£o ou sarc√°sticas n√£o afetar√£o os conceitos classificat√≥rios de nosso classificador, visto que os nossos conceitos de relev√¢ncia s√£o baseados na condi√ß√£o de demonstra√ß√£o de opini√£o. Ou seja, caso o tweet esteja relacionado a alguma forma de opini√£o, ele ser√° relevante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sugest√µes de melhorias (plano de expans√£o):\n",
    "- Uma sugest√£o de melhoria do classificador seria separar, dentre os tweets relevantes, os que falam positivamente do produto dos que falam negativamente, porque assim √© poss√≠vel ver potenciais melhorias no produto e tamb√©m fatores a serem mantidos nele. Para implementar essa mudan√ßa, pensamos em criar uma base de dados separada dos tweets relevantes, eliminando os neutros e irrelevantes das probabilidades.\n",
    "\n",
    "- Tamb√©m pensamos na utiliza√ß√£o de bigramas, ou at√© de trigramas (a probabilidade de 2 ou 3 palavras estarem juntas), m√©todo que pode aumentar a efic√°cia do classificador, pois considera a combina√ß√£o das palavras, j√° que existe um contexto na ocorr√™ncia de cada palavra. Essa melhoria pode diminuir a d√∫vida dos tweets neutros do nosso classificador. Isso poderia ser realizado criando, a partir dos pr√≥prios tweets, tabelas das combina√ß√µes de duas/tr√™s palavras consecutivas como cada elemento delas. (Fonte: [Naive Bayes and Text Classification I](https://arxiv.org/pdf/1410.5329.pdf) )\n",
    "\n",
    "- Outra melhoria que sugerimos √© o uso de probabilidades logar√≠tmicas para diminuir a parte decimal das probabilidades. Efetivo, pois, quando a parte decimal delas √© muito extensa, al√©m de haver risco de ocorrer \"overflow\", a combina√ß√£o delas fica absurdamente pequena, dificultando a compara√ß√£o entre probabilidades. Essa melhoria pode diminuir a d√∫vida dos tweets neutros do nosso classificador. Isso pode ser feito ao utilizar o logaritmo das frequ√™ncias para obter as probabilidades. (Fonte: [Naive Bayes and Text Classification I](https://arxiv.org/pdf/1410.5329.pdf) )\n",
    "\n",
    "- Sendo assim, para realizar nosso plano de expans√£o, seria necess√°ria uma maior capta√ß√£o de investimentos para ent√£o viabilizar as melhorias computacionais necess√°rias, visto que o m√©todo Naive-Bayes de classifica√ß√£o √© caracterizado como \"eager learner\", demandando assim uma capacidade computacional maior que outros m√©todos \"lazy learners\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N√£o podemos utilizar o classificador para gerar mais amostras de treinamento:\n",
    "- Caso fosse decidido por utilizar nosso classificador para gerar uma amostra maior de treinamento, o nosso classificador se tornaria enviesado, pois quando desejamos por obter uma base de dados maior, o nosso objetivo seria por aperfei√ßoar as probabilidades de relev√¢ncia de cada palavra, classificando manualmente. No entanto, caso utiliz√°ssemos o nosso classificador para gerar mais tweets, a relev√¢ncia de cada palavra n√£o seria necessariamente a correta, visto que nem sempre o classificador atribui a relev√¢ncia desejada, observado no teste de sentimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes em contextos diferentes do projeto:\n",
    "- Classifica√ß√£o de documentos (artigos, reportagens ou blogs), separando os tipos de produ√ß√£o textual, por meio das especificidades ortogr√°ficas e de design de cada um dos diferentes tipos de reportagem. Por exemplo, no caso de uma revista, tem-se uma ortografia mais informal e ligada a um p√∫blico-alvo. J√° um artigo cient√≠fico, tem-se o design dividido em t√≥picos comum a todos os artigos, assim como uma linguagem bastante formal e cient√≠fica.\n",
    "- Classifica√ß√£o de poemas com base nas especificidades de escrita de cada escola liter√°ria. Por exemplo, no arcadismo, era bastante comum a utiliza√ß√£o da frase: \"carpe diem\". Tamb√©m classificaremos com base no design do poema. Por exemplo, no parnasianismo, o adjetivo era utilizado em demasia, j√° na segunda gera√ß√£o do romantismo, palavras em tons depressivos ou que remetem √† tristeza, eram os mais comumente utilizados.\n",
    "- Tamb√©m √© poss√≠vel utilizar o Naive-Bayes no contexto de classifi√ß√£o de fake news. Pode-se fazer isso atrav√©s da an√°lise de alguns conceitos que pertencem √† quase todas not√≠cias falsas, como a falta de uma fonte confi√°vel ou a utiza√ß√£o de palavras bastante chamativas em demasia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* CHECK  Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* CHECK  Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CHECK  Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* CHECK  Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* CHECK  Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* CHECK  Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* CHECK  Montar um dashboard que realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
