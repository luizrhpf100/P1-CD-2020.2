{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Luiz Ricardo Hardman Paranhos\n",
    "\n",
    "Nome: Matheus Kwon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 2.5MB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for emoji: filename=emoji-0.6.0-cp37-none-any.whl size=49716 sha256=97f7a50807c1d14fe2aa92d84522ec13bab901b70c18179068198602755b5729\n",
      "  Stored in directory: /Users/matkwon/Library/Caches/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo cheetos.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'cheetos.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@eaipaixao_ cheetos obv</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@giovannapinto mano eu fui comprar 2 cheetos e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@zabele__ só tenho cheetos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@lilizvante cheetos, old\\nhttps://t.co/atamf2woj7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@biaventura14 kkkkkkkkkkkkkkkkkkkkk cheetos ve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  relevancia\n",
       "0                            @eaipaixao_ cheetos obv           2\n",
       "1  @giovannapinto mano eu fui comprar 2 cheetos e...           2\n",
       "2                         @zabele__ só tenho cheetos           1\n",
       "3  @lilizvante cheetos, old\\nhttps://t.co/atamf2woj7           1\n",
       "4  @biaventura14 kkkkkkkkkkkkkkkkkkkkk cheetos ve...           2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sou do tipo que quando tá conversando com algu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>att fresquinha de flaming hot cheetos!!!! http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>me entupindo de cheetos enquanto vejo tapas e ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cheetos ou doritos https://t.co/caytqjylnp</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mas quem colocou o cheetos na minha tml hoje ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  relevancia\n",
       "0  sou do tipo que quando tá conversando com algu...           0\n",
       "1  att fresquinha de flaming hot cheetos!!!! http...           1\n",
       "2  me entupindo de cheetos enquanto vejo tapas e ...           1\n",
       "3         cheetos ou doritos https://t.co/caytqjylnp           2\n",
       "4     mas quem colocou o cheetos na minha tml hoje ?           2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "- Relevante: informação da qual a empresa pode ganhar dinheiro\n",
    "- Neutro: informações sobre o salgadinho cheetos, mas que não necessariamente interessa à empresa\n",
    "- Irrelevante: resto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['relevancia'] = train['relevancia'].astype('category')\n",
    "train.relevancia.cat.categories = ['irrelevante', 'neutro', 'relevante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    # Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    # import string\n",
    "    punctuation = '[!-.:?;/,_@¿]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "def cleanup_enter(text):\n",
    "    punctuation = '\\n'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "def deEmojify(text):\n",
    "    # retirado do stackoverflow\n",
    "    em_split_emoji = emoji.get_emoji_regexp().split(text)\n",
    "    em_split_whitespace = [substr.split() for substr in em_split_emoji]\n",
    "    em_split = functools.reduce(operator.concat, em_split_whitespace)\n",
    "    p = ''\n",
    "    for separated in em_split:\n",
    "        p += separated + ' '\n",
    "    return p\n",
    "#    regrex_pattern = re.compile(pattern = \"[\"\n",
    "#        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                            \"]+\", flags = re.UNICODE)\n",
    "#    return regrex_pattern.sub(r'',text)\n",
    "    \n",
    "\n",
    "def link(text):\n",
    "    text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'@\\S+', '', text, flags=re.MULTILINE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# String com todas as palavras\n",
    "tweets_treinamento_raw = ''\n",
    "for tweet in train.Treinamento:\n",
    "    tweets_treinamento_raw = tweets_treinamento_raw + ' ' + tweet\n",
    "tweets_treinamento = deEmojify(cleanup_enter(cleanup(link(tweets_treinamento_raw.lower()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String com os relevantes\n",
    "filtro_relevante_train = train.relevancia == 'relevante'\n",
    "treinamento_relevante = train.loc[filtro_relevante_train,:]\n",
    "\n",
    "tweets_relevantes = ''\n",
    "for tweet in treinamento_relevante.Treinamento:\n",
    "    tweets_relevantes = tweets_relevantes + ' ' + tweet\n",
    "\n",
    "treinamento_relevante = deEmojify(cleanup_enter(cleanup(link(tweets_relevantes.lower()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String com os irrelevantes\n",
    "filtro_irrelevante_train = train.relevancia == 'irrelevante'\n",
    "treinamento_irrelevante = train.loc[filtro_irrelevante_train,:]\n",
    "\n",
    "tweets_irrelevantes = ''\n",
    "for tweet in treinamento_irrelevante.Treinamento:\n",
    "    tweets_irrelevantes = tweets_irrelevantes + ' ' + tweet\n",
    "\n",
    "    \n",
    "treinamento_irrelevante = deEmojify(cleanup_enter(cleanup(tweets_irrelevantes.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String com os neutros\n",
    "filtro_neutro_train = train.relevancia == 'neutro'\n",
    "treinamento_neutro = train.loc[filtro_neutro_train,:]\n",
    "\n",
    "tweets_neutro = ''\n",
    "for tweet in treinamento_neutro.Treinamento:\n",
    "    tweets_neutro = tweets_neutro + ' ' + tweet\n",
    "\n",
    "    \n",
    "treinamento_neutro = deEmojify(cleanup_enter(cleanup(tweets_neutro.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando lista e séries a partir das strings\n",
    "tweets_treinamento_lista = tweets_treinamento.split()\n",
    "treinamento_relevante_lista = treinamento_relevante.split()\n",
    "treinamento_irrelevante_lista = treinamento_irrelevante.split()\n",
    "treinamento_neutro_lista = treinamento_neutro.split()\n",
    "\n",
    "\n",
    "serie_treinamento = pd.Series(tweets_treinamento_lista)\n",
    "serie_treinamento_relevante = pd.Series(treinamento_relevante_lista)\n",
    "serie_treinamento_irrelevante = pd.Series(treinamento_irrelevante_lista)\n",
    "serie_treinamento_neutro = pd.Series(treinamento_neutro_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos    297\n",
       "de         171\n",
       "e          116\n",
       "um          81\n",
       "o           81\n",
       "          ... \n",
       "🥴            1\n",
       "migosss      1\n",
       "maconha      1\n",
       "ponto        1\n",
       "latim        1\n",
       "Length: 1261, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_treinamento = serie_treinamento.value_counts()\n",
    "tabela_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos      86\n",
       "de           49\n",
       "e            23\n",
       "requeijão    19\n",
       "o            18\n",
       "             ..\n",
       "🎃             1\n",
       "hmmm          1\n",
       "pqp           1\n",
       "mds           1\n",
       "agora         1\n",
       "Length: 287, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_treinamento_relevante = serie_treinamento_relevante.value_counts()\n",
    "tabela_treinamento_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['por', 'se','uma','em','mais','q','que','na','da','do','no','eu','de','e','o','um','a','com','pra', 'mas', 'só', 'so']\n",
    "def remove_stopwords(lista):\n",
    "    nova_lista = []\n",
    "    for palavra in lista:\n",
    "        x = 0\n",
    "        if palavra in stopwords:\n",
    "            x = 1\n",
    "        if x == 0:\n",
    "            # transformando verbos no gerúndio em verbos no infinitivo\n",
    "            if palavra[-3:] == 'ndo' or palavra[-3:] == 'mos':\n",
    "                if palavra == 'quando' or palavra == 'mando':\n",
    "                    nova_lista.append(palavra)\n",
    "                else:\n",
    "                    nova_lista.append(palavra[:-3]+'r')\n",
    "            elif palavra == 'n' or palavra == 'nao':\n",
    "                nova_lista.append('não')\n",
    "            elif palavra == 'ta' or palavra =='tá':\n",
    "                nova_lista.append('está')\n",
    "            else:\n",
    "                nova_lista.append(palavra)\n",
    "    return nova_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos      297\n",
       "é             60\n",
       "não           50\n",
       "comer         38\n",
       "requeijão     31\n",
       "doritos       26\n",
       "tem           26\n",
       "meu           23\n",
       "me            19\n",
       "gosto         14\n",
       "pq            13\n",
       "melhor        13\n",
       "minha         12\n",
       "vontade       12\n",
       "cheiro        12\n",
       "vou           12\n",
       "está          11\n",
       "como          11\n",
       "queijo        11\n",
       "fandangos     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_treinamento_stopwords_lista = remove_stopwords(tweets_treinamento_lista)\n",
    "        \n",
    "\n",
    "serie_treinamento_filtrado = pd.Series(tweets_treinamento_stopwords_lista)\n",
    "tabela_treinamento_filtrado = serie_treinamento_filtrado.value_counts()\n",
    "tabela_treinamento_filtrado_relativa = serie_treinamento_filtrado.value_counts(True)\n",
    "tabela_treinamento_filtrado.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos       86\n",
       "requeijão     19\n",
       "é             18\n",
       "doritos       16\n",
       "comer         13\n",
       "melhor        11\n",
       "vontade        9\n",
       "fandangos      8\n",
       "queria         7\n",
       "gosto          7\n",
       "😋              6\n",
       "sabor          5\n",
       "não            5\n",
       "bom            5\n",
       "salgadinho     4\n",
       "ruim           4\n",
       "🤤              4\n",
       "eh             4\n",
       "pq             4\n",
       "também         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo stop words da lista de todas as palavras relevantes\n",
    "treinamento_relevante_stopwords_lista = remove_stopwords(treinamento_relevante_lista)\n",
    "\n",
    "serie_treinamento_relevante_filtrado = pd.Series(treinamento_relevante_stopwords_lista)\n",
    "tabela_treinamento_relevante_filtrado = serie_treinamento_relevante_filtrado.value_counts()\n",
    "tabela_treinamento_relevante_filtrado_relativa = serie_treinamento_relevante_filtrado.value_counts(True)\n",
    "tabela_treinamento_relevante_filtrado.head(20)\n",
    "# palavras_relevantes_totais = len(tabela_treinamento_relevante_filtrado)\n",
    "# primeiras_relevantes = tabela_treinamento_relevante_filtrado.head(20)\n",
    "# P_Palavras = {}\n",
    "# for palavras, valor in primeiras_relevantes.items():\n",
    "#     P_Palavras[palavra] = (valor + 1) / (palavras_totais + palavras_relevantes_totais)\n",
    "# print(P_Palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos    116\n",
       "não         32\n",
       "é           24\n",
       "tem         13\n",
       "meu         11\n",
       "me          11\n",
       "cheiro      10\n",
       "está         8\n",
       "comer        8\n",
       "vou          7\n",
       "minha        7\n",
       "seu          7\n",
       "ele          7\n",
       "pq           6\n",
       "tipo         6\n",
       "aqui         6\n",
       "como         6\n",
       "queijo       5\n",
       "parece       5\n",
       "pelo         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo stop words da lista de todas as palavras irrelevantes\n",
    "treinamento_irrelevante_stopwords_lista = remove_stopwords(treinamento_irrelevante_lista)\n",
    "\n",
    "serie_treinamento_irrelevante_filtrado = pd.Series(treinamento_irrelevante_stopwords_lista)\n",
    "tabela_treinamento_irrelevante_filtrado = serie_treinamento_irrelevante_filtrado.value_counts()\n",
    "tabela_treinamento_irrelevante_filtrado_relativa = serie_treinamento_irrelevante_filtrado.value_counts(True)\n",
    "tabela_treinamento_irrelevante_filtrado.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos      95\n",
       "é            18\n",
       "comer        17\n",
       "não          13\n",
       "tem          11\n",
       "requeijão    10\n",
       "meu           9\n",
       "me            8\n",
       "doritos       7\n",
       "as            6\n",
       "1             5\n",
       "pacote        5\n",
       "gosto         5\n",
       "tudo          4\n",
       "lua           4\n",
       "chips         4\n",
       "mim           4\n",
       "come          4\n",
       "comi          4\n",
       "isso          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treinamento_neutro_stopwords_lista = remove_stopwords(treinamento_neutro_lista)\n",
    "\n",
    "serie_treinamento_neutro_filtrado = pd.Series(treinamento_neutro_stopwords_lista)\n",
    "tabela_treinamento_neutro_filtrado = serie_treinamento_neutro_filtrado.value_counts()\n",
    "tabela_treinamento_neutro_filtrado_relativa = serie_treinamento_neutro_filtrado.value_counts(True)\n",
    "tabela_treinamento_neutro_filtrado.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>relevancia</th>\n",
       "      <th>classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sou do tipo que quando tá conversando com algu...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>att fresquinha de flaming hot cheetos!!!! http...</td>\n",
       "      <td>1</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>me entupindo de cheetos enquanto vejo tapas e ...</td>\n",
       "      <td>1</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cheetos ou doritos https://t.co/caytqjylnp</td>\n",
       "      <td>2</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mas quem colocou o cheetos na minha tml hoje ?</td>\n",
       "      <td>2</td>\n",
       "      <td>irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>@bebediaboo eu muito li \"anti-cheetos\"</td>\n",
       "      <td>0</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>salgadinho, cheetos, biscoito recheado, biscoi...</td>\n",
       "      <td>0</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>queria experimentar takis e hot cheetos</td>\n",
       "      <td>1</td>\n",
       "      <td>neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>@lwttersondre cheetos de requeijão &amp;gt;&amp;gt;&amp;gt...</td>\n",
       "      <td>2</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>o cheetos azul é o melhor de todos e se você n...</td>\n",
       "      <td>2</td>\n",
       "      <td>relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  relevancia  \\\n",
       "0    sou do tipo que quando tá conversando com algu...           0   \n",
       "1    att fresquinha de flaming hot cheetos!!!! http...           1   \n",
       "2    me entupindo de cheetos enquanto vejo tapas e ...           1   \n",
       "3           cheetos ou doritos https://t.co/caytqjylnp           2   \n",
       "4       mas quem colocou o cheetos na minha tml hoje ?           2   \n",
       "..                                                 ...         ...   \n",
       "195             @bebediaboo eu muito li \"anti-cheetos\"           0   \n",
       "196  salgadinho, cheetos, biscoito recheado, biscoi...           0   \n",
       "197            queria experimentar takis e hot cheetos           1   \n",
       "198  @lwttersondre cheetos de requeijão &gt;&gt;&gt...           2   \n",
       "199  o cheetos azul é o melhor de todos e se você n...           2   \n",
       "\n",
       "    classificador  \n",
       "0          neutro  \n",
       "1          neutro  \n",
       "2     irrelevante  \n",
       "3       relevante  \n",
       "4     irrelevante  \n",
       "..            ...  \n",
       "195     relevante  \n",
       "196        neutro  \n",
       "197        neutro  \n",
       "198     relevante  \n",
       "199     relevante  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_R = len(treinamento_relevante_stopwords_lista) / len(tweets_treinamento_stopwords_lista)\n",
    "P_Rc = len(treinamento_irrelevante_stopwords_lista) / len(tweets_treinamento_stopwords_lista)\n",
    "P_N = len(treinamento_neutro_stopwords_lista) / len(tweets_treinamento_stopwords_lista)\n",
    "classificador = []\n",
    "def testar (tweet):\n",
    "    P_tweetDadoR = 1\n",
    "    P_tweetDadoRc = 1\n",
    "    P_tweetDadoN = 1\n",
    "    for palavra in tweet_teste:\n",
    "        # verifica se a palavra existe no relevante\n",
    "        if palavra in tabela_treinamento_relevante_filtrado:\n",
    "            P_tweetDadoR = P_tweetDadoR*(tabela_treinamento_relevante_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_relevante_filtrado))\n",
    "            # verifica se a palavra existe no irrelevante e no relevante\n",
    "            if palavra in tabela_treinamento_irrelevante_filtrado:\n",
    "                P_tweetDadoRc = P_tweetDadoRc*(tabela_treinamento_irrelevante_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_irrelevante_filtrado))\n",
    "                # verifica se a palavra existe no irrelevante, neutro e relevante\n",
    "                if palavra in tabela_treinamento_neutro_filtrado:\n",
    "                    P_tweetDadoN = P_tweetDadoN*(tabela_treinamento_neutro_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "                # se não existe a palavra no neutro, considera-se frequência 0\n",
    "                else:\n",
    "                    P_tweetDadoN = P_tweetDadoN / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "            # se não existe a palavra no irrelevante, considera-se frequencia 0\n",
    "            else:\n",
    "                P_tweetDadoRc = P_tweetDadoRc / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_irrelevante_filtrado)) \n",
    "                 # verifica se a palavra existe no neutro e relevante\n",
    "                if palavra in tabela_treinamento_neutro_filtrado:\n",
    "                    P_tweetDadoN = P_tweetDadoN*(tabela_treinamento_neutro_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "                # se não existe a palavra no neutro, considera-se frequência 0\n",
    "                else:\n",
    "                    P_tweetDadoN = P_tweetDadoN / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "        else:\n",
    "            # se n existe a palavra no relevante, considera-se frequência 0\n",
    "            P_tweetDadoR = P_tweetDadoR / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_relevante_filtrado))\n",
    "             # verifica se a palavra existe no irrelevante\n",
    "            if palavra in tabela_treinamento_irrelevante_filtrado:\n",
    "                P_tweetDadoRc = P_tweetDadoRc*(tabela_treinamento_irrelevante_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_irrelevante_filtrado))\n",
    "                 # verifica se a palavra existe no irrelevante e neutro \n",
    "                if palavra in tabela_treinamento_neutro_filtrado:\n",
    "                    P_tweetDadoN = P_tweetDadoN*(tabela_treinamento_neutro_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "                # se não existe a palavra no neutro, considera-se frequência 0\n",
    "                else:\n",
    "                    P_tweetDadoN = P_tweetDadoN / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "\n",
    "            # se n existe a palavra no irrelevante, considera-se frequência 0\n",
    "            else:\n",
    "                P_tweetDadoRc = P_tweetDadoRc / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_irrelevante_filtrado))\n",
    "                 # verifica se a palavra existe no neutro\n",
    "                if palavra in tabela_treinamento_neutro_filtrado:\n",
    "                    P_tweetDadoN = P_tweetDadoN*(tabela_treinamento_neutro_filtrado[palavra]+1) / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "                # se não existe a palavra no neutro, considera-se frequência 0\n",
    "                else:\n",
    "                    P_tweetDadoN = P_tweetDadoN / (len(tabela_treinamento_filtrado)+len(tabela_treinamento_neutro_filtrado))\n",
    "    P_RDadoTweet = P_tweetDadoR * P_R\n",
    "    P_RcDadoTweet = P_tweetDadoRc * P_Rc\n",
    "    P_NdadoTweet = P_tweetDadoN * P_N\n",
    "    if P_RDadoTweet >= P_RcDadoTweet:\n",
    "        if P_RDadoTweet >=  P_NdadoTweet:\n",
    "            classificador.append('relevante')\n",
    "        else:\n",
    "            classificador.append('neutro')\n",
    "    else:\n",
    "        if P_RcDadoTweet > P_NdadoTweet:\n",
    "            classificador.append('irrelevante')\n",
    "        else:\n",
    "            classificador.append('neutro')\n",
    "\n",
    "for tweet in test.Teste:\n",
    "    tweet_teste = remove_stopwords(deEmojify(cleanup_enter(cleanup(link(tweet.lower())))).split())\n",
    "    testar(tweet_teste)\n",
    "test['classificador'] = classificador\n",
    "test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classificador</th>\n",
       "      <th>irrelevante</th>\n",
       "      <th>neutro</th>\n",
       "      <th>relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relevancia</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.220779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.144928</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classificador  irrelevante    neutro  relevante\n",
       "relevancia                                     \n",
       "0                 0.506494  0.272727   0.220779\n",
       "1                 0.351852  0.388889   0.259259\n",
       "2                 0.144928  0.231884   0.623188"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimento = pd.crosstab(test.relevancia, test.classificador, normalize='index')\n",
    "sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobre o classificador:\n",
    "- O nosso classificador performa de forma razoável para classificar os tweets, principalmente os relevantes. No entanto, em relação aos tweets classificados como neutros e irrelevantes, a chance de nosso classificador errar será maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como são tratadas mensagens de dupla negação ou sarcasmo:\n",
    "- Quanto aos tweets que contém dupla negação e sarcasmo, nosso classificador funcionará na maioria das vezes, pois tweets que contém palavras de negação ou sarcásticas não afetarão os conceitos classificatórios de nosso classificador, visto que os nossos conceitos de relevância são baseados na condição de demonstração de opinião. Ou seja, caso o tweet esteja relacionado a alguma forma de opinião, ele será relevante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sugestões de melhorias (plano de expansão):\n",
    "- Uma sugestão de melhoria do classificador seria separar, dentre os tweets relevantes, os que falam positivamente do produto dos que falam negativamente. Para implementar essa mudança, pensamos em criar uma base de dados separada dos tweets relevantes, eliminando os neutros e irrelevantes das probabilidades.\n",
    "\n",
    "- Também pensamos na utilização de bigramas, ou até de trigramas (a probabilidade de combinação de 2 ou 3 palavras). Isso poderia ser realizado com algumas mudanças no próprio código do classificador. (Fonte: [Naive Bayes and Text Classification I](https://arxiv.org/pdf/1410.5329.pdf) )\n",
    "\n",
    "- Outra melhoria que sugerimos é o uso de probabilidades logarítmicas para diminuir o risco de ocorrer \"overflow\". Isso pode ser feito ao utilizar o logaritmo das frequências para obter as probabilidades. (Fonte: [Naive Bayes and Text Classification I](https://arxiv.org/pdf/1410.5329.pdf) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Não podemos utilizar o classificador para gerar mais amostras de treinamento:\n",
    "- Caso fosse decidido por utilizar nosso classificador para gerar uma amostra maior de treinamento, o nosso classificador se tornaria enviesado, pois quando desejamos por obter uma base de dados maior, o nosso objetivo seria por aperfeiçoar as probabilidades de relevância de cada palavra, classificando manualmente. No entanto, caso utilizássemos o nosso classificador para gerar mais tweets, a relevância de cada palavra não seria necessariamente a correta, visto que nem sempre o classificador atribui a relevância desejada, observado no teste de sentimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes em contextos diferentes do projeto:\n",
    "- Classificação de documentos (artigos, reportagens ou blogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
