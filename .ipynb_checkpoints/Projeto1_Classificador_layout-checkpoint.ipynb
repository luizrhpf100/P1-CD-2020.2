{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Luiz Ricardo Hardman Paranhos\n",
    "\n",
    "Nome: Matheus Kwon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo cheetos.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'cheetos.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@eaipaixao_ cheetos obv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@giovannapinto mano eu fui comprar 2 cheetos e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@zabele__ s√≥ tenho cheetos</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@lilizvante cheetos, old\\nhttps://t.co/atamf2woj7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@biaventura14 kkkkkkkkkkkkkkkkkkkkk cheetos ve...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  relevancia\n",
       "0                            @eaipaixao_ cheetos obv         1.0\n",
       "1  @giovannapinto mano eu fui comprar 2 cheetos e...         1.0\n",
       "2                         @zabele__ s√≥ tenho cheetos         0.0\n",
       "3  @lilizvante cheetos, old\\nhttps://t.co/atamf2woj7         0.0\n",
       "4  @biaventura14 kkkkkkkkkkkkkkkkkkkkk cheetos ve...         1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>relevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sou do tipo que quando t√° conversando com algu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>att fresquinha de flaming hot cheetos!!!! http...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>me entupindo de cheetos enquanto vejo tapas e ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cheetos ou doritos https://t.co/caytqjylnp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mas quem colocou o cheetos na minha tml hoje ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  relevancia\n",
       "0  sou do tipo que quando t√° conversando com algu...           0\n",
       "1  att fresquinha de flaming hot cheetos!!!! http...           0\n",
       "2  me entupindo de cheetos enquanto vejo tapas e ...           0\n",
       "3         cheetos ou doritos https://t.co/caytqjylnp           0\n",
       "4     mas quem colocou o cheetos na minha tml hoje ?           0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "- Relevante: informa√ß√£o da qual a empresa pode ganhar dinheiro\n",
    "- Irrelevante: resto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['relevancia'] = train['relevancia'].astype('category')\n",
    "train.relevancia.cat.categories = ['irrelevante', 'relevante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;/,_@¬ø]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "\n",
    "def cleanup_enter(text):\n",
    "    punctuation = '\\n'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                            \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def link(text):\n",
    "    text = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'@\\S+', '', text, flags=re.MULTILINE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# String com todas as palavras\n",
    "tweets_treinamento_raw = ''\n",
    "for tweet in train.Treinamento:\n",
    "    tweets_treinamento_raw = tweets_treinamento_raw + ' ' + tweet\n",
    "tweets_treinamento = deEmojify(cleanup_enter(cleanup(link(tweets_treinamento_raw.lower()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String com os relevantes\n",
    "filtro_relevante_train = train.relevancia == 'relevante'\n",
    "treinamento_relevante = train.loc[filtro_relevante_train,:]\n",
    "\n",
    "tweets_relevantes = ''\n",
    "for tweet in treinamento_relevante.Treinamento:\n",
    "    tweets_relevantes = tweets_relevantes + ' ' + tweet\n",
    "\n",
    "treinamento_relevante = deEmojify(cleanup_enter(cleanup(link(tweets_relevantes.lower()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String com os irrelevantes\n",
    "filtro_irrelevante_train = train.relevancia == 'irrelevante'\n",
    "treinamento_irrelevante = train.loc[filtro_irrelevante_train,:]\n",
    "\n",
    "tweets_irrelevantes = ''\n",
    "for tweet in treinamento_irrelevante.Treinamento:\n",
    "    tweets_irrelevantes = tweets_irrelevantes + ' ' + tweet\n",
    "\n",
    "    \n",
    "treinamento_irrelevante = deEmojify(cleanup_enter(cleanup(tweets_irrelevantes.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando lista e s√©ries a partir das strings\n",
    "tweets_treinamento_lista = tweets_treinamento.split()\n",
    "treinamento_relevante_lista = treinamento_relevante.split()\n",
    "treinamento_irrelevante_lista = treinamento_irrelevante.split()\n",
    "\n",
    "serie_treinamento = pd.Series(tweets_treinamento_lista)\n",
    "serie_treinamento_relevante = pd.Series(treinamento_relevante_lista)\n",
    "serie_treinamento_irrelevante = pd.Series(treinamento_irrelevante_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos    297\n",
       "de         171\n",
       "e          116\n",
       "um          81\n",
       "o           81\n",
       "          ... \n",
       "stans        1\n",
       "doritim      1\n",
       "maya         1\n",
       "humild       1\n",
       "ot√°rios      1\n",
       "Length: 1236, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_treinamento = serie_treinamento.value_counts()\n",
    "tabela_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos    151\n",
       "de          92\n",
       "e           48\n",
       "um          39\n",
       "eu          31\n",
       "          ... \n",
       "ü§§            1\n",
       "obv          1\n",
       "meche        1\n",
       "‚Äî            1\n",
       "jantar       1\n",
       "Length: 554, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_treinamento_relevante = serie_treinamento_relevante.value_counts()\n",
    "tabela_treinamento_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['por', 'se','uma','em','mais','q','que','na','da','do','no','eu','de','e','o','um','a','com','pra', 'mas', 's√≥', 'so']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos      0.114407\n",
       "√©            0.023112\n",
       "n√£o          0.019260\n",
       "comer        0.014638\n",
       "requeij√£o    0.011941\n",
       "doritos      0.010015\n",
       "tem          0.010015\n",
       "meu          0.008860\n",
       "me           0.007319\n",
       "gosto        0.005393\n",
       "pq           0.005008\n",
       "melhor       0.005008\n",
       "minha        0.004622\n",
       "vontade      0.004622\n",
       "cheiro       0.004622\n",
       "vou          0.004622\n",
       "como         0.004237\n",
       "queijo       0.004237\n",
       "pacote       0.003852\n",
       "fandangos    0.003852\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo stop words da lista de todas as palavras\n",
    "tweets_treinamento_stopwords_lista = []\n",
    "for palavra in tweets_treinamento_lista:\n",
    "    x = 0\n",
    "    if palavra in stopwords:\n",
    "        x = 1\n",
    "    if x == 0:\n",
    "        if palavra[-3:] == 'ndo' or palavra[-3:] == 'mos':\n",
    "            tweets_treinamento_stopwords_lista.append(palavra[:-3]+'r')\n",
    "        elif palavra == 'n' or palavra == 'nao':\n",
    "            tweets_treinamento_stopwords_lista.append('n√£o')\n",
    "        else:\n",
    "            tweets_treinamento_stopwords_lista.append(palavra)\n",
    "        \n",
    "\n",
    "serie_treinamento_filtrado = pd.Series(tweets_treinamento_stopwords_lista)\n",
    "tabela_treinamento_filtrado = serie_treinamento_filtrado.value_counts(True)\n",
    "tabela_treinamento_filtrado.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos       0.140204\n",
       "√©             0.027855\n",
       "requeij√£o     0.025998\n",
       "comer         0.022284\n",
       "doritos       0.017642\n",
       "gosto         0.011142\n",
       "meu           0.010214\n",
       "melhor        0.010214\n",
       "vontade       0.010214\n",
       "queria        0.009285\n",
       "n√£o           0.009285\n",
       "tem           0.008357\n",
       "fandangos     0.007428\n",
       "me            0.007428\n",
       "ou            0.006500\n",
       "sabor         0.006500\n",
       "pacote        0.006500\n",
       "pq            0.006500\n",
       "salgadinho    0.006500\n",
       "bom           0.005571\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo stop words da lista de todas as palavras relevantes\n",
    "treinamento_relevante_stopwords_lista = []\n",
    "for palavra in treinamento_relevante_lista:\n",
    "    x = 0\n",
    "    if palavra in stopwords:\n",
    "        x = 1\n",
    "    if x == 0:\n",
    "        if palavra[-3:] == 'ndo' or palavra[-3:] == 'mos':\n",
    "            treinamento_relevante_stopwords_lista.append(palavra[:-3]+'r')\n",
    "        elif palavra == 'n' or palavra == 'nao':\n",
    "            treinamento_relevante_stopwords_lista.append('n√£o')\n",
    "        else:\n",
    "            treinamento_relevante_stopwords_lista.append(palavra)\n",
    "\n",
    "serie_treinamento_relevante_filtrado = pd.Series(treinamento_relevante_stopwords_lista)\n",
    "tabela_treinamento_relevante_filtrado = serie_treinamento_relevante_filtrado.value_counts(True)\n",
    "tabela_treinamento_relevante_filtrado.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cheetos     0.087139\n",
       "n√£o         0.024038\n",
       "√©           0.018029\n",
       "tem         0.010216\n",
       "comer       0.008413\n",
       "meu         0.007212\n",
       "me          0.006611\n",
       "cheiro      0.006010\n",
       "vou         0.006010\n",
       "ele         0.005409\n",
       "como        0.004808\n",
       "minha       0.004808\n",
       "seu         0.004207\n",
       "tipo        0.004207\n",
       "aqui        0.004207\n",
       "as          0.003606\n",
       "doritos     0.003606\n",
       "vc          0.003606\n",
       "pq          0.003606\n",
       "fazer       0.003606\n",
       "comprar     0.003005\n",
       "queijo      0.003005\n",
       "os          0.003005\n",
       "vai         0.003005\n",
       "parece      0.003005\n",
       "isso        0.003005\n",
       "pelo        0.003005\n",
       "estar       0.003005\n",
       "biscoito    0.003005\n",
       "essa        0.003005\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo stop words da lista de todas as palavras irrelevantes\n",
    "treinamento_irrelevante_stopwords_lista = []\n",
    "for palavra in treinamento_irrelevante_lista:\n",
    "    x = 0\n",
    "    if palavra in stopwords:\n",
    "        x = 1\n",
    "    if x == 0:\n",
    "        if palavra[-3:] == 'ndo' or palavra[-3:] == 'mos':\n",
    "            treinamento_irrelevante_stopwords_lista.append(palavra[:-3]+'r')\n",
    "        elif palavra == 'n' or palavra == 'nao':\n",
    "            treinamento_irrelevante_stopwords_lista.append('n√£o')\n",
    "        else:\n",
    "            treinamento_irrelevante_stopwords_lista.append(palavra)\n",
    "\n",
    "serie_treinamento_irrelevante_filtrado = pd.Series(treinamento_irrelevante_stopwords_lista)\n",
    "tabela_treinamento_irrelevante_filtrado = serie_treinamento_irrelevante_filtrado.value_counts(True)\n",
    "tabela_treinamento_irrelevante_filtrado.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R): 0.41486902927580893\n",
      "P(Rc): 0.5851309707241911\n",
      "1.0\n",
      "P(R|Requeijao): 0.9032258064516128\n",
      "P(Rc|Requeijao): 0.08834134615384615\n",
      "0.9915671526054589\n"
     ]
    }
   ],
   "source": [
    "P_R = len(treinamento_relevante_stopwords_lista) / len(tweets_treinamento_stopwords_lista)\n",
    "print('P(R):',P_R)\n",
    "P_Rc = 1 - P_R\n",
    "print('P(Rc):',P_Rc)\n",
    "print(P_R + P_Rc)\n",
    "\n",
    "P_RequeijaoDadoR = tabela_treinamento_relevante_filtrado['requeij√£o']\n",
    "P_Requeijao = tabela_treinamento_filtrado['requeij√£o']\n",
    "P_RDadoRequeijao = P_RequeijaoDadoR * P_R / P_Requeijao\n",
    "print('P(R|Requeijao):',P_RDadoRequeijao)\n",
    "\n",
    "P_RequeijaoDadoRc = tabela_treinamento_irrelevante_filtrado['requeij√£o']\n",
    "P_RcDadoRequeijao = P_RequeijaoDadoRc * P_Rc / P_Requeijao\n",
    "print('P(Rc|Requeijao):',P_RcDadoRequeijao)\n",
    "\n",
    "# print(P_RequeijaoDadoRc)\n",
    "# print(P_RequeijaoDadoR)\n",
    "print(P_RDadoRequeijao+P_RcDadoRequeijao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R|Doritos): 0.7307692307692307\n",
      "P(Rc|Doritos): 0.21066013313609466\n",
      "0.9414293639053254\n"
     ]
    }
   ],
   "source": [
    "P_DoritosDadoR = tabela_treinamento_relevante_filtrado['doritos']\n",
    "P_Doritos = tabela_treinamento_filtrado['doritos']\n",
    "P_RDadoDoritos = P_DoritosDadoR * P_R / P_Doritos\n",
    "print('P(R|Doritos):',P_RDadoDoritos)\n",
    "\n",
    "P_DoritosDadoRc = tabela_treinamento_irrelevante_filtrado['doritos']\n",
    "P_RcDadoDoritos = P_DoritosDadoRc * P_Rc / P_Doritos\n",
    "print('P(Rc|Doritos):',P_RcDadoDoritos)\n",
    "\n",
    "# print(P_DoritosDadoRc)\n",
    "# print(P_DoritosDadoR)\n",
    "print(P_RDadoDoritos+P_RcDadoDoritos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R|Comer): 0.6315789473684211\n",
      "P(Rc|Comer): 0.3363170546558705\n",
      "0.9678960020242916\n"
     ]
    }
   ],
   "source": [
    "P_ComerDadoR = tabela_treinamento_relevante_filtrado['comer']\n",
    "P_Comer = tabela_treinamento_filtrado['comer']\n",
    "P_RDadoComer = P_ComerDadoR * P_R / P_Comer\n",
    "print('P(R|Comer):',P_RDadoComer)\n",
    "\n",
    "P_ComerDadoRc = tabela_treinamento_irrelevante_filtrado['comer']\n",
    "P_RcDadoComer = P_ComerDadoRc * P_Rc / P_Comer\n",
    "print('P(Rc|Comer):',P_RcDadoComer)\n",
    "\n",
    "# print(P_ComerDadoRc)\n",
    "# print(P_ComerDadoR)\n",
    "print(P_RDadoComer+P_RcDadoComer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R|Cheiro): 0.16666666666666666\n",
      "P(Rc|Cheiro): 0.7607171474358974\n",
      "0.927383814102564\n"
     ]
    }
   ],
   "source": [
    "P_CheiroDadoR = tabela_treinamento_relevante_filtrado['cheiro']\n",
    "P_Cheiro = tabela_treinamento_filtrado['cheiro']\n",
    "P_RDadoCheiro = P_CheiroDadoR * P_R / P_Cheiro\n",
    "print('P(R|Cheiro):',P_RDadoCheiro)\n",
    "\n",
    "P_CheiroDadoRc = tabela_treinamento_irrelevante_filtrado['cheiro']\n",
    "P_RcDadoCheiro = P_CheiroDadoRc * P_Rc / P_Cheiro\n",
    "print('P(Rc|Cheiro):',P_RcDadoCheiro)\n",
    "\n",
    "# print(P_CheiroDadoRc)\n",
    "# print(P_CheiroDadoR)\n",
    "print(P_RDadoCheiro+P_RcDadoCheiro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R|Salgadinho): 0.7777777777777777\n",
      "P(Rc|Salgadinho): 0.20285790598290598\n",
      "0.9806356837606837\n"
     ]
    }
   ],
   "source": [
    "P_SalgadinhoDadoR = tabela_treinamento_relevante_filtrado['salgadinho']\n",
    "P_Salgadinho = tabela_treinamento_filtrado['salgadinho']\n",
    "P_RDadoSalgadinho = P_SalgadinhoDadoR * P_R / P_Salgadinho\n",
    "print('P(R|Salgadinho):',P_RDadoSalgadinho)\n",
    "\n",
    "P_SalgadinhoDadoRc = tabela_treinamento_irrelevante_filtrado['salgadinho']\n",
    "P_RcDadoSalgadinho = P_SalgadinhoDadoRc * P_Rc / P_Salgadinho\n",
    "print('P(Rc|Salgadinho):',P_RcDadoSalgadinho)\n",
    "\n",
    "# print(P_SalgadinhoDadoRc)\n",
    "# print(P_SalgadinhoDadoR)\n",
    "print(P_RDadoSalgadinho+P_RcDadoSalgadinho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R|nao): 0.19999999999999998\n",
      "P(Rc|nao): 0.7302884615384616\n",
      "0.9302884615384616\n"
     ]
    }
   ],
   "source": [
    "P_naoDadoR = tabela_treinamento_relevante_filtrado['n√£o']\n",
    "P_nao = tabela_treinamento_filtrado['n√£o']\n",
    "P_RDadonao = P_naoDadoR * P_R / P_nao\n",
    "print('P(R|nao):',P_RDadonao)\n",
    "\n",
    "P_naoDadoRc = tabela_treinamento_irrelevante_filtrado['n√£o']\n",
    "P_RcDadonao = P_naoDadoRc * P_Rc / P_nao\n",
    "print('P(Rc|nao):',P_RcDadonao)\n",
    "\n",
    "# print(P_SalgadinhoDadoRc)\n",
    "# print(P_SalgadinhoDadoR)\n",
    "print(P_RDadonao+P_RcDadonao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R|biscoito): 0.2857142857142857\n",
      "P(Rc|biscoito): 0.6520432692307692\n",
      "0.9377575549450549\n"
     ]
    }
   ],
   "source": [
    "P_biscoitoDadoR = tabela_treinamento_relevante_filtrado['biscoito']\n",
    "P_biscoito = tabela_treinamento_filtrado['biscoito']\n",
    "P_RDadobiscoito = P_biscoitoDadoR * P_R / P_biscoito\n",
    "print('P(R|biscoito):',P_RDadobiscoito)\n",
    "\n",
    "P_biscoitoDadoRc = tabela_treinamento_irrelevante_filtrado['biscoito']\n",
    "P_RcDadobiscoito = P_biscoitoDadoRc * P_Rc / P_biscoito\n",
    "print('P(Rc|biscoito):',P_RcDadobiscoito)\n",
    "\n",
    "# print(P_SalgadinhoDadoRc)\n",
    "# print(P_SalgadinhoDadoR)\n",
    "print(P_RDadobiscoito+P_RcDadobiscoito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R|comprar): 0.4444444444444445\n",
      "P(Rc|comprar): 0.5071447649572649\n",
      "0.9515892094017093\n"
     ]
    }
   ],
   "source": [
    "P_comprarDadoR = tabela_treinamento_relevante_filtrado['comprar']\n",
    "P_comprar = tabela_treinamento_filtrado['comprar']\n",
    "P_RDadocomprar = P_comprarDadoR * P_R / P_comprar\n",
    "print('P(R|comprar):',P_RDadocomprar)\n",
    "\n",
    "P_comprarDadoRc = tabela_treinamento_irrelevante_filtrado['comprar']\n",
    "P_RcDadocomprar = P_comprarDadoRc * P_Rc / P_comprar\n",
    "print('P(Rc|comprar):',P_RcDadocomprar)\n",
    "\n",
    "# print(P_SalgadinhoDadoRc)\n",
    "# print(P_SalgadinhoDadoR)\n",
    "print(P_RDadocomprar+P_RcDadocomprar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R|queijo): 0.5454545454545455\n",
      "P(Rc|queijo): 0.4149366258741259\n",
      "0.9603911713286715\n"
     ]
    }
   ],
   "source": [
    "P_queijoDadoR = tabela_treinamento_relevante_filtrado['queijo']\n",
    "P_queijo = tabela_treinamento_filtrado['queijo']\n",
    "P_RDadoqueijo = P_queijoDadoR * P_R / P_queijo\n",
    "print('P(R|queijo):',P_RDadoqueijo)\n",
    "\n",
    "P_queijoDadoRc = tabela_treinamento_irrelevante_filtrado['queijo']\n",
    "P_RcDadoqueijo = P_queijoDadoRc * P_Rc / P_queijo\n",
    "print('P(Rc|queijo):',P_RcDadoqueijo)\n",
    "\n",
    "# print(P_SalgadinhoDadoRc)\n",
    "# print(P_SalgadinhoDadoR)\n",
    "print(P_RDadoqueijo+P_RcDadoqueijo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(R|melhor): 0.8461538461538461\n",
      "P(Rc|melhor): 0.14044008875739647\n",
      "0.9865939349112426\n"
     ]
    }
   ],
   "source": [
    "P_melhorDadoR = tabela_treinamento_relevante_filtrado['melhor']\n",
    "P_melhor = tabela_treinamento_filtrado['melhor']\n",
    "P_RDadomelhor = P_melhorDadoR * P_R / P_melhor\n",
    "print('P(R|melhor):',P_RDadomelhor)\n",
    "\n",
    "P_melhorDadoRc = tabela_treinamento_irrelevante_filtrado['melhor']\n",
    "P_RcDadomelhor = P_melhorDadoRc * P_Rc / P_melhor\n",
    "print('P(Rc|melhor):',P_RcDadomelhor)\n",
    "\n",
    "# print(P_SalgadinhoDadoRc)\n",
    "# print(P_SalgadinhoDadoR)\n",
    "print(P_RDadomelhor+P_RcDadomelhor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'comendo'\n",
    "print(string[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
